diff --git a/node_modules/node-llama-cpp/dist/bindings/getLlama.js b/node_modules/node-llama-cpp/dist/bindings/getLlama.js
index 81b9d40..f5d1d53 100644
--- a/node_modules/node-llama-cpp/dist/bindings/getLlama.js
+++ b/node_modules/node-llama-cpp/dist/bindings/getLlama.js
@@ -1,6 +1,7 @@
 import process from "process";
 import path from "path";
 import console from "console";
+import sea from 'node:sea'
 import { createRequire } from "module";
 import { builtinLlamaCppGitHubRepo, builtinLlamaCppRelease, defaultLlamaCppLogLevel, defaultLlamaCppGitHubRepo, defaultLlamaCppGpuSupport, defaultLlamaCppRelease, defaultSkipDownload, llamaLocalBuildBinsDirectory, recommendedBaseDockerImage, defaultLlamaCppDebugMode } from "../config.js";
 import { getConsoleLogPrefix } from "../utils/getConsoleLogPrefix.js";
@@ -464,6 +465,8 @@ function loadBindingModule(bindingModulePath) {
 }
 function getShouldTestBinaryBeforeLoading({ isPrebuiltBinary, platform, platformInfo, buildMetadata }) {
     if (platform === "linux") {
+        // AZ - when we're running as a SEA this causes execution to fail on Linux
+        if (sea.isSea()) { return false }
         if (isPrebuiltBinary)
             return true;
         if (platformInfo.name !== buildMetadata.buildOptions.platformInfo.name ||
diff --git a/node_modules/node-llama-cpp/dist/index.d.ts b/node_modules/node-llama-cpp/dist/index.d.ts
index dac8368..4189493 100644
--- a/node_modules/node-llama-cpp/dist/index.d.ts
+++ b/node_modules/node-llama-cpp/dist/index.d.ts
@@ -1,6 +1,6 @@
 import { DisposedError } from "lifecycle-utils";
 import { Llama } from "./bindings/Llama.js";
-import { getLlama, type LlamaOptions, type LastBuildOptions } from "./bindings/getLlama.js";
+import { getLlama, getLlamaForOptions, type LlamaOptions, type LastBuildOptions } from "./bindings/getLlama.js";
 import { NoBinaryFoundError } from "./bindings/utils/NoBinaryFoundError.js";
 import { type LlamaGpuType, LlamaLogLevel, LlamaLogLevelGreaterThan, LlamaLogLevelGreaterThanOrEqual, LlamaVocabularyType } from "./bindings/types.js";
 import { resolveModelFile, type ResolveModelFileOptions } from "./utils/resolveModelFile.js";
@@ -62,4 +62,4 @@ import { GgmlType, type GgufTensorInfo } from "./gguf/types/GgufTensorInfoTypes.
 import { type ModelFileAccessTokens } from "./utils/modelFileAccesTokens.js";
 import { type OverridesObject } from "./utils/OverridesObject.js";
 import type { LlamaClasses } from "./utils/getLlamaClasses.js";
-export { Llama, getLlama, type LlamaOptions, type LastBuildOptions, type LlamaGpuType, type LlamaClasses, LlamaLogLevel, NoBinaryFoundError, resolveModelFile, type ResolveModelFileOptions, LlamaModel, LlamaModelTokens, LlamaModelInfillTokens, TokenAttributes, type LlamaModelOptions, LlamaGrammar, type LlamaGrammarOptions, LlamaJsonSchemaGrammar, LlamaJsonSchemaValidationError, LlamaGrammarEvaluationState, type LlamaGrammarEvaluationStateOptions, LlamaContext, LlamaContextSequence, type LlamaContextOptions, type SequenceEvaluateOptions, type BatchingOptions, type CustomBatchingDispatchSchedule, type CustomBatchingPrioritizationStrategy, type BatchItem, type PrioritizedBatchItem, type ContextShiftOptions, type ContextTokensDeleteRange, type EvaluationPriority, type SequenceEvaluateMetadataOptions, type SequenceEvaluateOutput, type LlamaContextSequenceRepeatPenalty, type ControlledEvaluateInputItem, type ControlledEvaluateIndexOutput, TokenBias, LlamaEmbeddingContext, type LlamaEmbeddingContextOptions, LlamaEmbedding, type LlamaEmbeddingOptions, type LlamaEmbeddingJSON, LlamaRankingContext, type LlamaRankingContextOptions, LlamaChatSession, defineChatSessionFunction, type LlamaChatSessionOptions, type LlamaChatSessionContextShiftOptions, type LLamaChatPromptOptions, type LLamaChatCompletePromptOptions, type LlamaChatSessionRepeatPenalty, type LLamaChatPreloadPromptOptions, LlamaChat, type LlamaChatOptions, type LLamaChatGenerateResponseOptions, type LLamaChatLoadAndCompleteUserMessageOptions, type LLamaChatContextShiftOptions, type LLamaContextualRepeatPenalty, type LlamaChatResponse, type LlamaChatResponseFunctionCall, type LlamaChatLoadAndCompleteUserResponse, LlamaChatSessionPromptCompletionEngine, type LLamaChatPromptCompletionEngineOptions, LlamaCompletion, type LlamaCompletionOptions, type LlamaCompletionGenerationOptions, type LlamaInfillGenerationOptions, type LlamaCompletionResponse, TokenMeter, type TokenMeterState, UnsupportedError, InsufficientMemoryError, DisposedError, ChatWrapper, type ChatWrapperSettings, type ChatWrapperGenerateContextStateOptions, type ChatWrapperGeneratedContextState, type ChatWrapperGenerateInitialHistoryOptions, EmptyChatWrapper, Llama3_2LightweightChatWrapper, Llama3_1ChatWrapper, Llama3ChatWrapper, Llama2ChatWrapper, MistralChatWrapper, GeneralChatWrapper, ChatMLChatWrapper, FalconChatWrapper, AlpacaChatWrapper, FunctionaryChatWrapper, GemmaChatWrapper, TemplateChatWrapper, type TemplateChatWrapperOptions, JinjaTemplateChatWrapper, type JinjaTemplateChatWrapperOptions, type JinjaTemplateChatWrapperOptionsConvertMessageFormat, type ChatHistoryFunctionCallMessageTemplate, resolveChatWrapper, type BuiltInChatWrapperType, type ResolveChatWrapperOptions, resolvableChatWrapperTypeNames, type ResolvableChatWrapperTypeName, specializedChatWrapperTypeNames, type SpecializedChatWrapperTypeName, templateChatWrapperTypeNames, type TemplateChatWrapperTypeName, chatWrappers, ChatModelFunctionsDocumentationGenerator, LlamaText, SpecialTokensText, SpecialToken, isLlamaText, tokenizeText, type LlamaTextValue, type LlamaTextInputValue, type LlamaTextJSON, type LlamaTextJSONValue, type LlamaTextSpecialTokensTextJSON, type LlamaTextSpecialTokenJSON, type BuiltinSpecialTokenValue, TokenPredictor, DraftSequenceTokenPredictor, InputLookupTokenPredictor, appendUserMessageToChatHistory, getModuleVersion, type ChatHistoryItem, type ChatModelFunctionCall, type ChatModelFunctions, type ChatModelResponse, type ChatSessionModelFunction, type ChatSessionModelFunctions, type ChatSystemMessage, type ChatUserMessage, type Token, type Tokenizer, type Detokenizer, isChatModelResponseFunctionCall, type GbnfJsonSchema, type GbnfJsonSchemaToType, type GbnfJsonSchemaImmutableType, type GbnfJsonBasicSchema, type GbnfJsonConstSchema, type GbnfJsonEnumSchema, type GbnfJsonBasicStringSchema, type GbnfJsonFormatStringSchema, type GbnfJsonStringSchema, type GbnfJsonOneOfSchema, type GbnfJsonObjectSchema, type GbnfJsonArraySchema, LlamaVocabularyType, LlamaLogLevelGreaterThan, LlamaLogLevelGreaterThanOrEqual, readGgufFileInfo, type GgufFileInfo, type GgufMetadata, type GgufTensorInfo, type GgufMetadataLlmToType, GgufArchitectureType, GgufFileType, GgufMetadataTokenizerTokenType, GgufMetadataArchitecturePoolingType, type GgufMetadataGeneral, type GgufMetadataTokenizer, type GgufMetadataDefaultArchitectureType, type GgufMetadataLlmLLaMA, type GgufMetadataMPT, type GgufMetadataGPTNeoX, type GgufMetadataGPTJ, type GgufMetadataGPT2, type GgufMetadataBloom, type GgufMetadataFalcon, type GgufMetadataMamba, GgmlType, isGgufMetadataOfArchitectureType, GgufInsights, type GgufInsightsResourceRequirements, GgufInsightsConfigurationResolver, createModelDownloader, ModelDownloader, type ModelDownloaderOptions, type ModelFileAccessTokens, combineModelDownloaders, CombinedModelDownloader, type CombinedModelDownloaderOptions, jsonDumps, type OverridesObject, experimentalChunkDocument };
+export { Llama, getLlama, getLlamaForOptions, type LlamaOptions, type LastBuildOptions, type LlamaGpuType, type LlamaClasses, LlamaLogLevel, NoBinaryFoundError, resolveModelFile, type ResolveModelFileOptions, LlamaModel, LlamaModelTokens, LlamaModelInfillTokens, TokenAttributes, type LlamaModelOptions, LlamaGrammar, type LlamaGrammarOptions, LlamaJsonSchemaGrammar, LlamaJsonSchemaValidationError, LlamaGrammarEvaluationState, type LlamaGrammarEvaluationStateOptions, LlamaContext, LlamaContextSequence, type LlamaContextOptions, type SequenceEvaluateOptions, type BatchingOptions, type CustomBatchingDispatchSchedule, type CustomBatchingPrioritizationStrategy, type BatchItem, type PrioritizedBatchItem, type ContextShiftOptions, type ContextTokensDeleteRange, type EvaluationPriority, type SequenceEvaluateMetadataOptions, type SequenceEvaluateOutput, type LlamaContextSequenceRepeatPenalty, type ControlledEvaluateInputItem, type ControlledEvaluateIndexOutput, TokenBias, LlamaEmbeddingContext, type LlamaEmbeddingContextOptions, LlamaEmbedding, type LlamaEmbeddingOptions, type LlamaEmbeddingJSON, LlamaRankingContext, type LlamaRankingContextOptions, LlamaChatSession, defineChatSessionFunction, type LlamaChatSessionOptions, type LlamaChatSessionContextShiftOptions, type LLamaChatPromptOptions, type LLamaChatCompletePromptOptions, type LlamaChatSessionRepeatPenalty, type LLamaChatPreloadPromptOptions, LlamaChat, type LlamaChatOptions, type LLamaChatGenerateResponseOptions, type LLamaChatLoadAndCompleteUserMessageOptions, type LLamaChatContextShiftOptions, type LLamaContextualRepeatPenalty, type LlamaChatResponse, type LlamaChatResponseFunctionCall, type LlamaChatLoadAndCompleteUserResponse, LlamaChatSessionPromptCompletionEngine, type LLamaChatPromptCompletionEngineOptions, LlamaCompletion, type LlamaCompletionOptions, type LlamaCompletionGenerationOptions, type LlamaInfillGenerationOptions, type LlamaCompletionResponse, TokenMeter, type TokenMeterState, UnsupportedError, InsufficientMemoryError, DisposedError, ChatWrapper, type ChatWrapperSettings, type ChatWrapperGenerateContextStateOptions, type ChatWrapperGeneratedContextState, type ChatWrapperGenerateInitialHistoryOptions, EmptyChatWrapper, Llama3_2LightweightChatWrapper, Llama3_1ChatWrapper, Llama3ChatWrapper, Llama2ChatWrapper, MistralChatWrapper, GeneralChatWrapper, ChatMLChatWrapper, FalconChatWrapper, AlpacaChatWrapper, FunctionaryChatWrapper, GemmaChatWrapper, TemplateChatWrapper, type TemplateChatWrapperOptions, JinjaTemplateChatWrapper, type JinjaTemplateChatWrapperOptions, type JinjaTemplateChatWrapperOptionsConvertMessageFormat, type ChatHistoryFunctionCallMessageTemplate, resolveChatWrapper, type BuiltInChatWrapperType, type ResolveChatWrapperOptions, resolvableChatWrapperTypeNames, type ResolvableChatWrapperTypeName, specializedChatWrapperTypeNames, type SpecializedChatWrapperTypeName, templateChatWrapperTypeNames, type TemplateChatWrapperTypeName, chatWrappers, ChatModelFunctionsDocumentationGenerator, LlamaText, SpecialTokensText, SpecialToken, isLlamaText, tokenizeText, type LlamaTextValue, type LlamaTextInputValue, type LlamaTextJSON, type LlamaTextJSONValue, type LlamaTextSpecialTokensTextJSON, type LlamaTextSpecialTokenJSON, type BuiltinSpecialTokenValue, TokenPredictor, DraftSequenceTokenPredictor, InputLookupTokenPredictor, appendUserMessageToChatHistory, getModuleVersion, type ChatHistoryItem, type ChatModelFunctionCall, type ChatModelFunctions, type ChatModelResponse, type ChatSessionModelFunction, type ChatSessionModelFunctions, type ChatSystemMessage, type ChatUserMessage, type Token, type Tokenizer, type Detokenizer, isChatModelResponseFunctionCall, type GbnfJsonSchema, type GbnfJsonSchemaToType, type GbnfJsonSchemaImmutableType, type GbnfJsonBasicSchema, type GbnfJsonConstSchema, type GbnfJsonEnumSchema, type GbnfJsonBasicStringSchema, type GbnfJsonFormatStringSchema, type GbnfJsonStringSchema, type GbnfJsonOneOfSchema, type GbnfJsonObjectSchema, type GbnfJsonArraySchema, LlamaVocabularyType, LlamaLogLevelGreaterThan, LlamaLogLevelGreaterThanOrEqual, readGgufFileInfo, type GgufFileInfo, type GgufMetadata, type GgufTensorInfo, type GgufMetadataLlmToType, GgufArchitectureType, GgufFileType, GgufMetadataTokenizerTokenType, GgufMetadataArchitecturePoolingType, type GgufMetadataGeneral, type GgufMetadataTokenizer, type GgufMetadataDefaultArchitectureType, type GgufMetadataLlmLLaMA, type GgufMetadataMPT, type GgufMetadataGPTNeoX, type GgufMetadataGPTJ, type GgufMetadataGPT2, type GgufMetadataBloom, type GgufMetadataFalcon, type GgufMetadataMamba, GgmlType, isGgufMetadataOfArchitectureType, GgufInsights, type GgufInsightsResourceRequirements, GgufInsightsConfigurationResolver, createModelDownloader, ModelDownloader, type ModelDownloaderOptions, type ModelFileAccessTokens, combineModelDownloaders, CombinedModelDownloader, type CombinedModelDownloaderOptions, jsonDumps, type OverridesObject, experimentalChunkDocument };
diff --git a/node_modules/node-llama-cpp/dist/index.js b/node_modules/node-llama-cpp/dist/index.js
index 7ac4693..3399f20 100644
--- a/node_modules/node-llama-cpp/dist/index.js
+++ b/node_modules/node-llama-cpp/dist/index.js
@@ -1,6 +1,6 @@
 import { DisposedError } from "lifecycle-utils";
 import { Llama } from "./bindings/Llama.js";
-import { getLlama } from "./bindings/getLlama.js";
+import { getLlama, getLlamaForOptions } from "./bindings/getLlama.js";
 import { NoBinaryFoundError } from "./bindings/utils/NoBinaryFoundError.js";
 import { LlamaLogLevel, LlamaLogLevelGreaterThan, LlamaLogLevelGreaterThanOrEqual, LlamaVocabularyType } from "./bindings/types.js";
 import { resolveModelFile } from "./utils/resolveModelFile.js";
@@ -55,5 +55,5 @@ import { experimentalChunkDocument } from "./evaluator/utils/chunkDocument.js";
 import { isChatModelResponseFunctionCall } from "./types.js";
 import { GgufArchitectureType, GgufFileType, GgufMetadataTokenizerTokenType, GgufMetadataArchitecturePoolingType, isGgufMetadataOfArchitectureType } from "./gguf/types/GgufMetadataTypes.js";
 import { GgmlType } from "./gguf/types/GgufTensorInfoTypes.js";
-export { Llama, getLlama, LlamaLogLevel, NoBinaryFoundError, resolveModelFile, LlamaModel, LlamaModelTokens, LlamaModelInfillTokens, TokenAttributes, LlamaGrammar, LlamaJsonSchemaGrammar, LlamaJsonSchemaValidationError, LlamaGrammarEvaluationState, LlamaContext, LlamaContextSequence, TokenBias, LlamaEmbeddingContext, LlamaEmbedding, LlamaRankingContext, LlamaChatSession, defineChatSessionFunction, LlamaChat, LlamaChatSessionPromptCompletionEngine, LlamaCompletion, TokenMeter, UnsupportedError, InsufficientMemoryError, DisposedError, ChatWrapper, EmptyChatWrapper, Llama3_2LightweightChatWrapper, Llama3_1ChatWrapper, Llama3ChatWrapper, Llama2ChatWrapper, MistralChatWrapper, GeneralChatWrapper, ChatMLChatWrapper, FalconChatWrapper, AlpacaChatWrapper, FunctionaryChatWrapper, GemmaChatWrapper, TemplateChatWrapper, JinjaTemplateChatWrapper, resolveChatWrapper, resolvableChatWrapperTypeNames, specializedChatWrapperTypeNames, templateChatWrapperTypeNames, chatWrappers, ChatModelFunctionsDocumentationGenerator, LlamaText, SpecialTokensText, SpecialToken, isLlamaText, tokenizeText, TokenPredictor, DraftSequenceTokenPredictor, InputLookupTokenPredictor, appendUserMessageToChatHistory, getModuleVersion, isChatModelResponseFunctionCall, LlamaVocabularyType, LlamaLogLevelGreaterThan, LlamaLogLevelGreaterThanOrEqual, readGgufFileInfo, GgufArchitectureType, GgufFileType, GgufMetadataTokenizerTokenType, GgufMetadataArchitecturePoolingType, GgmlType, isGgufMetadataOfArchitectureType, GgufInsights, GgufInsightsConfigurationResolver, createModelDownloader, ModelDownloader, combineModelDownloaders, CombinedModelDownloader, jsonDumps, experimentalChunkDocument };
+export { Llama, getLlama, getLlamaForOptions, LlamaLogLevel, NoBinaryFoundError, resolveModelFile, LlamaModel, LlamaModelTokens, LlamaModelInfillTokens, TokenAttributes, LlamaGrammar, LlamaJsonSchemaGrammar, LlamaJsonSchemaValidationError, LlamaGrammarEvaluationState, LlamaContext, LlamaContextSequence, TokenBias, LlamaEmbeddingContext, LlamaEmbedding, LlamaRankingContext, LlamaChatSession, defineChatSessionFunction, LlamaChat, LlamaChatSessionPromptCompletionEngine, LlamaCompletion, TokenMeter, UnsupportedError, InsufficientMemoryError, DisposedError, ChatWrapper, EmptyChatWrapper, Llama3_2LightweightChatWrapper, Llama3_1ChatWrapper, Llama3ChatWrapper, Llama2ChatWrapper, MistralChatWrapper, GeneralChatWrapper, ChatMLChatWrapper, FalconChatWrapper, AlpacaChatWrapper, FunctionaryChatWrapper, GemmaChatWrapper, TemplateChatWrapper, JinjaTemplateChatWrapper, resolveChatWrapper, resolvableChatWrapperTypeNames, specializedChatWrapperTypeNames, templateChatWrapperTypeNames, chatWrappers, ChatModelFunctionsDocumentationGenerator, LlamaText, SpecialTokensText, SpecialToken, isLlamaText, tokenizeText, TokenPredictor, DraftSequenceTokenPredictor, InputLookupTokenPredictor, appendUserMessageToChatHistory, getModuleVersion, isChatModelResponseFunctionCall, LlamaVocabularyType, LlamaLogLevelGreaterThan, LlamaLogLevelGreaterThanOrEqual, readGgufFileInfo, GgufArchitectureType, GgufFileType, GgufMetadataTokenizerTokenType, GgufMetadataArchitecturePoolingType, GgmlType, isGgufMetadataOfArchitectureType, GgufInsights, GgufInsightsConfigurationResolver, createModelDownloader, ModelDownloader, combineModelDownloaders, CombinedModelDownloader, jsonDumps, experimentalChunkDocument };
 //# sourceMappingURL=index.js.map
\ No newline at end of file
